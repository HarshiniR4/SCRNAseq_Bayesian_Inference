### `neg_binom.ipynb` – Detailed Documentation

---

#### 1  Objective

`neg_binom.ipynb` implements the **hierarchical Negative-Binomial (NB) Bayesian model** used to detect condition-specific expression changes in the merged microglia single-cell dataset produced earlier (`combined_by_obs.h5ad`).
Key goals:

1. **Model raw UMI counts** while accounting for over-dispersion and library size.
2. Borrow statistical strength across **genes** *and* **cells / experimental conditions**.
3. Produce posterior distributions for log-fold changes that can be propagated to downstream gene-set enrichment.

---

#### 2  Input Artefacts

| File                   | Description                                 | Generated by          |
| ---------------------- | ------------------------------------------- | --------------------- |
| `combined_by_obs.h5ad` | 186 224 cells × 39 241 genes AnnData object | `combine_adata.ipynb` |
| `gene_lengths.tsv`     | Lengths in bp (used for offset)             | Extract step          |
| `cond_design.csv`      | Mapping of `cell_id` → `condition`/`batch`  | Manual or QC notebook |

---

#### 3  Software Stack

| Package                    | Version (tested) | Notes                            |
| -------------------------- | ---------------- | -------------------------------- |
| **PyMC**                   | 5.10             | Probabilistic programming        |
| **Aesara**                 | 2.10             | Computational graph backend      |
| **ArviZ**                  | 0.17             | Diagnostics & posterior plotting |
| **Scanpy / AnnData**       | ≥ 1.10           | Data I/O                         |
| **NumPy / Pandas / SciPy** | latest           | Back-end ops                     |

Install:

```bash
conda env create -f envs/pymc.yml          # YAML provided in repo
conda activate scrna_nb
```

YAML pins the BLAS libraries to avoid mismatch errors on HPC.

---

#### 4  Model Specification

Let

* $y_{ig}$ = UMI count for cell *i*, gene *g*
* $s_i$ = library size (total UMIs) for cell *i*
* $L_g$ = gene length (kb) for gene *g*
* $c_i$ ∈ {0, 1} indicator of experimental condition

**Linear predictor**

$$
\log(\mu_{ig}) = \beta_{0g} + \beta_{1g}\,c_i + \gamma_g \,\log L_g + \log s_i +
                 \alpha_i
$$

* $\beta_{0g}$ baseline log-expression
* $\beta_{1g}$ condition log-fold change (target parameter)
* $\gamma_g$ gene-length coefficient (shared hyper-prior)
* $\alpha_i$ cell-level random intercept (captures residual library/quality)

**Likelihood**

$$
y_{ig} \sim \text{NB}\!\bigl(\text{mean}=\mu_{ig},\;\text{dispersion}=\phi_g\bigr)
$$

where $\phi_g$ is gene-specific over-dispersion.

**Priors**

| Parameter    | Prior                                     |
| ------------ | ----------------------------------------- |
| $\beta_{0g}$ | Normal(2.0, 1.0)                          |
| $\beta_{1g}$ | Normal(0, 1.0)                            |
| $\gamma_g$   | Truncated Normal(0, 1.0)                  |
| $\phi_g$     | Half-Cauchy(2.0)                          |
| $\alpha_i$   | Normal(0, σ\_α), σ\_α \~ Half-Normal(1.0) |

A **non-centred re-parameterisation** is used for all σ-hierarchies to improve sampling.

---

#### 5  Notebook Workflow

| Stage                                                         | Cell(s) | Details                                                                                                                                                                |
| ------------------------------------------------------------- | ------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Load data**                                                 | 2-3     | Reads AnnData in backed mode; computes `library_size` and selects *highly variable genes* (HVGs = top 3 000) to reduce memory                                          |
| **Minibatch iterator**                                        | 4-6     | Builds a generator that yields **(counts, gene\_idx, cond\_idx)** slices of 512 cells × 3 000 genes; powers stochastic VI                                              |
| **Model context**                                             | 7       | Defines PyMC model exactly as above using `pm.Data` holders for minibatching                                                                                           |
| **Inference**                                                 | 8       | Runs *automatic differentiation variational inference* (`pm.fit`) for 15 000 updates, learning-rate 1e-3, `callback=pm.callbacks.CheckParametersConvergence(tol=1e-2)` |
| **Posterior draws**                                           | 9       | Converts the final approximation to 2 000 posterior samples via `approx.sample()`                                                                                      |
| **Diagnostics**                                               | 10-12   | • Rank histograms                                                                                                                                                      |
| • ELBO trace                                                  |         |                                                                                                                                                                        |
| • Posterior predictive checks on held-out cells               |         |                                                                                                                                                                        |
| **Save artefacts**                                            | Final   | Saves:                                                                                                                                                                 |
| `nb_trace.nc` (ArviZ netCDF)                                  |         |                                                                                                                                                                        |
| `posterior_ppc.h5ad` (AnnData with posterior predictive mean) |         |                                                                                                                                                                        |

Runtime ≈ 35 min on a single NVIDIA A6000 or \~4 hrs CPU-only.

---

#### 6  Output Interpretation

* **`az.summary()`** on `β_1g` gives median log-fold change and 94 % HDI.
  Positive values = up-regulated in condition 1.
* **Volcano Plot** – Cell `[18]` creates `log2FC` vs. `–log10(q-value)`; genes beyond |log2FC|>0.5 & FDR<0.05 are highlighted.
* **Posterior predictive** overlay confirms that simulated counts match empirical mean-variance trend.

---

#### 7  Running the Notebook

```bash
jupyter lab src/neg_binom.ipynb
# In the toolbar: "Kernel ▶ Restart & Run All"
```

> **GPU** strongly recommended. Set `JAX_PLATFORM_NAME=gpu` for CUDA devices; otherwise PyMC falls back to CPU Aesara.

---

#### 8  Troubleshooting

| Symptom                                 | Reason                  | Fix                                                          |
| --------------------------------------- | ----------------------- | ------------------------------------------------------------ |
| `MemoryError` when allocating minibatch | HVG slice still too big | Reduce `N_HVG` to 2 000                                      |
| ELBO plateaus but variance large        | Learning-rate too high  | Lower to 5e-4; increase updates                              |
| Posterior predictive over-dispersed     | Poor φ\_g prior         | Use Half-Normal(1.0) or add hierarchical prior on dispersion |

---

#### 9  Next Steps

1. **Gene-set Enrichment** – `analysis/enrichment.Rmd` imports `β_1g` posteriors and performs GSEA (fgsea).
2. **Cell-level Effects** – Extend model with cell-type specific slope (`β_{1gk}`) for subtype-aware DE.
3. **Model Comparison** – See `src/zinb_reg.ipynb` for zero-inflated NB baseline.

---

#### 10  References

* Browning *et al.* (2023) *Hierarchical Bayesian Models for scRNA-seq*, BioRxiv.
* Carpenter *et al.* (2017) *Stan: A probabilistic programming language*, JSS.
* Wolf *et al.* (2018) *Scanpy: large-scale single-cell gene expression data analysis*, Nat Methods.

---
